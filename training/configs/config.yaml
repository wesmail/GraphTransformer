seed_everything: 42
trainer:
  max_epochs: 25
  accelerator: "gpu"
  devices: [0,1,2,3]
  strategy: "ddp_find_unused_parameters_false"
  precision: "16-mixed"  # mixed-precision training
  accumulate_grad_batches: 2
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_weights_only: false
        mode: "min"
        monitor: "val_loss"
        every_n_train_steps: 0
        every_n_epochs: 1
        train_time_interval: null
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "val_loss"
        min_delta: 0.0
        patience: 4
        verbose: false
  logger:
    - class_path: lightning.pytorch.loggers.TensorBoardLogger
      init_args:
        save_dir: "."
        name: "toptagging_checkpoints"

model:
  class_path: models.models.JetTaggingModule
  init_args:
    in_channels: 7
    u_channels: 6
    num_pnet_layers: 3
    pnet_embed_dims: [32, 64, 128]
    knn: [4, 8, 16]
    num_blocks: 8
    num_heads:  8
    lr: 0.0015
    t_max: 25
    eta_min: 1e-5
    batch_size: 128

data:
  class_path: data.data_handling.JetTaggingDataModule
  init_args:
    data_dir: "/scratch/tmp/wesmail/Higgs/training/data/"
    file_list: ["train_graph.h5", "val_graph.h5", "test_graph.h5"]
    batch_size: 128
    num_workers: 16

